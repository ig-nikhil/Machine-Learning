{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35a55b62-4b18-40a9-bc71-d5ddc3d0f744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def initialize_weights(input_dim, hidden_layers, output_dim):\n",
    "    weights = {}\n",
    "    layers_dims = [input_dim] + hidden_layers + [output_dim]\n",
    "    for i in range(1, len(layers_dims)):\n",
    "        weights['W' + str(i)] = np.random.randn(layers_dims[i], layers_dims[i-1]) * 0.01\n",
    "        weights['b' + str(i)] = np.zeros((layers_dims[i], 1))\n",
    "    return weights\n",
    "\n",
    "def forward_propagation(X, weights):\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(weights) // 2\n",
    "    for l in range(1, L):\n",
    "        A_prev = A\n",
    "        Z = np.dot(weights['W' + str(l)], A_prev) + weights['b' + str(l)]\n",
    "        A = sigmoid(Z)\n",
    "        caches.append((A_prev, Z))\n",
    "    Z_last = np.dot(weights['W' + str(L)], A) + weights['b' + str(L)]\n",
    "    AL = Z_last # Linear activation for the last layer\n",
    "    caches.append((A, Z_last))\n",
    "    return AL, caches\n",
    "\n",
    "def compute_cost(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "    cost = np.sum((AL - Y) ** 2) / (2 * m)\n",
    "    return cost\n",
    "\n",
    "def backward_propagation(AL, Y, caches, weights):\n",
    "    grads = {}\n",
    "    L = len(caches)\n",
    "    m = AL.shape[1]\n",
    "    dAL = (AL - Y)\n",
    "    current_cache = caches[L - 1]\n",
    "    A_prev, Z_last = current_cache\n",
    "    grads['dW' + str(L)] = np.dot(dAL, A_prev.T) / m\n",
    "    grads['db' + str(L)] = np.sum(dAL, axis=1, keepdims=True) / m\n",
    "    dA = np.dot(weights['W' + str(L)].T, dAL)\n",
    "    for l in reversed(range(L - 1)):\n",
    "        current_cache = caches[l]\n",
    "        A_prev, Z = current_cache\n",
    "        dZ = dA * sigmoid_derivative(Z)\n",
    "        grads['dW' + str(l + 1)] = np.dot(dZ, A_prev.T) / m\n",
    "        grads['db' + str(l + 1)] = np.sum(dZ, axis=1, keepdims=True) / m\n",
    "        dA = np.dot(weights['W' + str(l + 1)].T, dZ)\n",
    "    return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6158f8b5-4753-45da-9d89-b17056ec7d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xor_gate():\n",
    "    # Input and output data\n",
    "    X = np.array([[0, 0, 1, 1], [0, 1, 0, 1]])\n",
    "    Y = np.array([[0, 1, 1, 0]])\n",
    "    \n",
    "    # Define network architecture\n",
    "    input_dim = X.shape[0]\n",
    "    hidden_layers = [10, 10, 10, 10, 10]  # 5 hidden layers with 10 nodes each\n",
    "    output_dim = Y.shape[0]\n",
    "    \n",
    "    # Initialize weights\n",
    "    weights = initialize_weights(input_dim, hidden_layers, output_dim)\n",
    "    \n",
    "    # Training parameters\n",
    "    learning_rate = 0.01\n",
    "    num_iterations = 10000\n",
    "    \n",
    "    # Training loop\n",
    "    for i in range(num_iterations):\n",
    "        # Forward propagation\n",
    "        AL, caches = forward_propagation(X, weights)\n",
    "        \n",
    "        # Compute cost\n",
    "        cost = compute_cost(AL, Y)\n",
    "        \n",
    "        # Backward propagation\n",
    "        grads = backward_propagation(AL, Y, caches, weights)\n",
    "        \n",
    "        # Update weights\n",
    "        for key in weights.keys():\n",
    "            weights[key] -= learning_rate * grads['d' + key]\n",
    "        \n",
    "        # Print cost every 1000 iterations\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Iteration {i}, Cost: {cost}\")\n",
    "    \n",
    "    # Test the trained model\n",
    "    AL, _ = forward_propagation(X, weights)\n",
    "    print(\"Final predictions:\")\n",
    "    print(AL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75fb545d-7e11-42e6-a47a-d4982ab9c047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Cost: 0.25347020441342155\n",
      "Iteration 1000, Cost: 0.125\n",
      "Iteration 2000, Cost: 0.12500000000000003\n",
      "Iteration 3000, Cost: 0.125\n",
      "Iteration 4000, Cost: 0.125\n",
      "Iteration 5000, Cost: 0.125\n",
      "Iteration 6000, Cost: 0.12499999999999999\n",
      "Iteration 7000, Cost: 0.125\n",
      "Iteration 8000, Cost: 0.125\n",
      "Iteration 9000, Cost: 0.125\n",
      "Final predictions:\n",
      "[[0.5 0.5 0.5 0.5]]\n"
     ]
    }
   ],
   "source": [
    "xor_gate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5249b03-c607-4ea1-abe3-0b248218413c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
