{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5249b03-c607-4ea1-abe3-0b248218413c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial hidden weights: [0.15193954 0.63166312 0.97857378 0.36117987 0.673271   0.39604932\n",
      " 0.24370126 0.40380877 0.60309592 0.72826288 0.38219649 0.88905882\n",
      " 0.72109665 0.35745631 0.43650489 0.8853669  0.39311027 0.95400039\n",
      " 0.62613786 0.25283163] [0.81783128 0.83549616 0.32402245 0.03348848 0.6955241  0.5283476\n",
      " 0.1219841  0.37578404 0.16752429 0.32662395 0.2451231  0.62038409\n",
      " 0.9503363  0.83478371 0.30374712 0.18401375 0.45583608 0.15298881\n",
      " 0.41060466 0.85733301]\n",
      "Initial hidden biases: [0.48010445 0.12435016 0.21140399 0.09483321 0.50097381 0.61523687\n",
      " 0.43327628 0.59731437 0.88713101 0.53209593 0.01991145 0.28604723\n",
      " 0.82708672 0.43296636 0.08445359 0.62105857 0.9549127  0.42951187\n",
      " 0.96717522 0.8410298 ]\n",
      "Initial output weights: [0.17412345] [0.90489075] [0.52571999] [0.04331026] [0.79908061] [0.60419164] [0.05715857] [0.5102556] [0.60119483] [0.22720779] [0.80695194] [0.79158374] [0.00735102] [0.93092754] [0.48584142] [0.83413005] [0.617483] [0.02328347] [0.46658666] [0.79223094]\n",
      "Initial output biases: [0.26710283]\n",
      "Final hidden weights: [-3.02674865  3.93968189  1.31935873  1.35234041  2.57936989  0.45253346\n",
      "  0.78488733  0.52272866  0.71441653  1.38710752  0.03316501  3.46218016\n",
      " -0.12622507  2.13231341  0.93790568  1.1015152   0.41309544  5.02825911\n",
      "  0.62130836  0.82482537] [ 5.15836989  3.90397469  0.37024683  1.05997854  2.53220734  0.63755269\n",
      "  0.85936907  0.56787114  0.1701525   0.1759814  -0.1759364   3.40302084\n",
      "  1.47176397  2.1357736   0.89715348  0.78730335  0.478698   -2.95170495\n",
      "  0.35534259  1.03079177]\n",
      "Final hidden bias: [ 1.03721718 -0.60070088 -0.52876707 -1.50955592  0.59190335  0.34250111\n",
      " -0.64445991  0.19450208  0.69807423 -0.31415676 -0.00437971 -0.20194851\n",
      "  0.11558862  0.89519025 -0.90900395  0.93793628  0.87543249  1.03157002\n",
      "  0.81852245  1.11015236]\n",
      "Final output weights: [-5.82015518] [4.77085195] [-1.15619344] [-2.23355213] [2.72331761] [-0.33458749] [-1.44095028] [-0.50416027] [-0.14520251] [-1.27471491] [0.4059523] [3.98263239] [-1.12223631] [2.10869322] [-1.4632477] [0.48437575] [0.06875269] [-5.48127177] [-0.04424573] [0.56946218]\n",
      "Final output bias: [0.51038815]\n",
      "\n",
      "Output from neural network after 10,000 epochs: [0.02793151] [0.95411233] [0.95381393] [0.05646354]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "#np.random.seed(0)\n",
    "\n",
    "def sigmoid (x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "#Input datasets\n",
    "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "expected_output = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "epochs = 10000\n",
    "lr = 0.1\n",
    "inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 2,20,1\n",
    "\n",
    "#Random weights and bias initialization\n",
    "hidden_weights = np.random.uniform(size=(inputLayerNeurons,hiddenLayerNeurons))\n",
    "hidden_bias =np.random.uniform(size=(1,hiddenLayerNeurons))\n",
    "output_weights = np.random.uniform(size=(hiddenLayerNeurons,outputLayerNeurons))\n",
    "output_bias = np.random.uniform(size=(1,outputLayerNeurons))\n",
    "\n",
    "print(\"Initial hidden weights: \",end='')\n",
    "print(*hidden_weights)\n",
    "print(\"Initial hidden biases: \",end='')\n",
    "print(*hidden_bias)\n",
    "print(\"Initial output weights: \",end='')\n",
    "print(*output_weights)\n",
    "print(\"Initial output biases: \",end='')\n",
    "print(*output_bias)\n",
    "\n",
    "\n",
    "#Training algorithm\n",
    "for _ in range(epochs):\n",
    "\t#Forward Propagation\n",
    "\thidden_layer_activation = np.dot(inputs,hidden_weights)\n",
    "\thidden_layer_activation += hidden_bias\n",
    "\thidden_layer_output = sigmoid(hidden_layer_activation)\n",
    "\n",
    "\toutput_layer_activation = np.dot(hidden_layer_output,output_weights)\n",
    "\toutput_layer_activation += output_bias\n",
    "\tpredicted_output = sigmoid(output_layer_activation)\n",
    "\n",
    "\t#Backpropagation\n",
    "\terror = expected_output - predicted_output\n",
    "\td_predicted_output = error * sigmoid_derivative(predicted_output)\n",
    "\t\n",
    "\terror_hidden_layer = d_predicted_output.dot(output_weights.T)\n",
    "\td_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "\t#Updating Weights and Biases\n",
    "\toutput_weights += hidden_layer_output.T.dot(d_predicted_output) * lr\n",
    "\toutput_bias += np.sum(d_predicted_output,axis=0,keepdims=True) * lr\n",
    "\thidden_weights += inputs.T.dot(d_hidden_layer) * lr\n",
    "\thidden_bias += np.sum(d_hidden_layer,axis=0,keepdims=True) * lr\n",
    "\n",
    "print(\"Final hidden weights: \",end='')\n",
    "print(*hidden_weights)\n",
    "print(\"Final hidden bias: \",end='')\n",
    "print(*hidden_bias)\n",
    "print(\"Final output weights: \",end='')\n",
    "print(*output_weights)\n",
    "print(\"Final output bias: \",end='')\n",
    "print(*output_bias)\n",
    "\n",
    "print(\"\\nOutput from neural network after 10,000 epochs: \",end='')\n",
    "print(*predicted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78a80b5-6fef-4d9a-b045-d5e2e14672fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
