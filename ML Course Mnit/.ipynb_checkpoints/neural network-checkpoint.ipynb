{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5249b03-c607-4ea1-abe3-0b248218413c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial hidden weights: [0.32099092 0.17811832 0.95969918 0.7259733  0.97700043 0.8299956\n",
      " 0.55813605 0.7007493  0.31039081 0.85993872 0.3752386  0.98515976\n",
      " 0.39662504 0.10610693 0.43532131 0.12528608 0.71648543 0.21903827\n",
      " 0.35360677 0.17499333] [0.69658954 0.72117853 0.38139088 0.66265805 0.00198893 0.58851527\n",
      " 0.21831366 0.60899745 0.51664793 0.50306153 0.38492173 0.33558497\n",
      " 0.24422449 0.83352546 0.33971895 0.1156163  0.69880967 0.26443745\n",
      " 0.64207231 0.93558297]\n",
      "Initial hidden biases: [0.42370538 0.89032163 0.49655399 0.63365999 0.17947514 0.87947655\n",
      " 0.87080995 0.81956983 0.42118588 0.53170837 0.0217691  0.4797782\n",
      " 0.6567295  0.84676841 0.13631828 0.25648126 0.37363616 0.54727024\n",
      " 0.41521966 0.48382129]\n",
      "Initial output weights: [0.74407778] [0.29458331] [0.41841623] [0.45897078] [0.8877687] [0.44351641] [0.08911022] [0.33055567] [0.1170143] [0.46459591] [0.05198732] [0.63659766] [0.35357242] [0.28544754] [0.22872188] [0.40543227] [0.08779305] [0.53694485] [0.14348271] [0.68589491]\n",
      "Initial output biases: [0.59492188]\n",
      "Epoch 0: Error = 0.49714243586792517\n",
      "Epoch 100: Error = 0.49351992680893275\n",
      "Epoch 200: Error = 0.2506496169398617\n",
      "Epoch 300: Error = 0.24999323746814478\n",
      "Epoch 400: Error = 0.2493582923604332\n",
      "Epoch 500: Error = 0.24872145002859505\n",
      "Epoch 600: Error = 0.24806393984863306\n",
      "Epoch 700: Error = 0.24736779642228734\n",
      "Epoch 800: Error = 0.24661482831544265\n",
      "Epoch 900: Error = 0.24578573671190462\n",
      "Epoch 1000: Error = 0.24485930975960532\n",
      "Epoch 1100: Error = 0.24381164739261468\n",
      "Epoch 1200: Error = 0.24261539415839162\n",
      "Epoch 1300: Error = 0.2412389776253945\n",
      "Epoch 1400: Error = 0.23964586751510303\n",
      "Epoch 1500: Error = 0.2377938824121258\n",
      "Epoch 1600: Error = 0.23563457024798962\n",
      "Epoch 1700: Error = 0.23311266896029115\n",
      "Epoch 1800: Error = 0.23016561400325308\n",
      "Epoch 1900: Error = 0.22672301285137125\n",
      "Epoch 2000: Error = 0.22270598494176083\n",
      "Epoch 2100: Error = 0.21802631554197305\n",
      "Epoch 2200: Error = 0.2125855487819357\n",
      "Epoch 2300: Error = 0.20627451485085213\n",
      "Epoch 2400: Error = 0.19897444751314447\n",
      "Epoch 2500: Error = 0.19056193067648736\n",
      "Epoch 2600: Error = 0.18092142850798487\n",
      "Epoch 2700: Error = 0.16997048429203446\n",
      "Epoch 2800: Error = 0.15770166395709492\n",
      "Epoch 2900: Error = 0.14423801124671795\n",
      "Epoch 3000: Error = 0.12988278616328736\n",
      "Epoch 3100: Error = 0.11512752243227914\n",
      "Epoch 3200: Error = 0.10058707993864607\n",
      "Epoch 3300: Error = 0.08687092446329514\n",
      "Epoch 3400: Error = 0.07444923690817465\n",
      "Epoch 3500: Error = 0.06357889561400497\n",
      "Epoch 3600: Error = 0.05430960879715892\n",
      "Epoch 3700: Error = 0.0465422326559147\n",
      "Epoch 3800: Error = 0.04009814983499709\n",
      "Epoch 3900: Error = 0.034773799081238704\n",
      "Epoch 4000: Error = 0.030373685819565142\n",
      "Epoch 4100: Error = 0.026725855037037283\n",
      "Epoch 4200: Error = 0.023686365478565497\n",
      "Epoch 4300: Error = 0.021138088072317904\n",
      "Epoch 4400: Error = 0.018987176032149736\n",
      "Epoch 4500: Error = 0.017158991978045636\n",
      "Epoch 4600: Error = 0.015594307614646499\n",
      "Epoch 4700: Error = 0.014246069201195342\n",
      "Epoch 4800: Error = 0.013076771980590941\n",
      "Epoch 4900: Error = 0.012056383216712483\n",
      "Epoch 5000: Error = 0.011160721784491012\n",
      "Epoch 5100: Error = 0.010370202346027962\n",
      "Epoch 5200: Error = 0.009668864179491605\n",
      "Converged at epoch 5200\n",
      "Final hidden weights: [ 2.26848223 -0.83405791  1.0727749   2.56114762  1.01388915  1.96117998\n",
      "  4.2482547   0.81132138  0.38703956  2.21886307  1.3092663   3.45084228\n",
      "  0.82885907 -2.32835308  1.10212863  0.52173976  0.78617619  0.40943756\n",
      "  0.23674047  1.85406781] [ 2.32792118  2.02503151  0.70672432  2.57442375  0.43837956  1.9361185\n",
      " -2.70314578  0.75541183  0.9899273   2.18817897  1.09477872  3.43970046\n",
      "  0.20006461  3.86024701  0.68340653  0.46127215  0.58423359  0.46902909\n",
      "  1.16523814  1.9916488 ]\n",
      "Final hidden bias: [ 0.50470567  0.55711204  0.59884632  0.29523966  0.05330575  0.83817557\n",
      "  1.15462746  0.90475154 -0.30004227  0.58061576 -1.57844664 -0.46984819\n",
      "  0.25521157  1.01215473 -0.89452056 -0.00213009 -0.32915057  0.30461698\n",
      " -0.25713728  0.74481206]\n",
      "Final output weights: [2.1870579] [-1.62816092] [0.07333424] [2.6009407] [-0.46875833] [1.7744192] [-4.52146696] [0.19109948] [-1.26851119] [2.03308929] [-2.30887636] [3.91479098] [-0.8029968] [-3.82451637] [-1.64681794] [-0.64936819] [-1.07392221] [-0.48914151] [-1.26948774] [1.62002711]\n",
      "Final output bias: [0.20727788]\n",
      "\n",
      "Output from neural network after 10,000 epochs: [0.06913086] [0.8995204] [0.90192909] [0.11920066]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Input datasets\n",
    "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "expected_output = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "epochs = 10000\n",
    "lr = 0.1\n",
    "inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 2, 20, 1\n",
    "\n",
    "# Random weights and bias initialization\n",
    "hidden_weights = np.random.uniform(size=(inputLayerNeurons, hiddenLayerNeurons))\n",
    "hidden_bias = np.random.uniform(size=(1, hiddenLayerNeurons))\n",
    "output_weights = np.random.uniform(size=(hiddenLayerNeurons, outputLayerNeurons))\n",
    "output_bias = np.random.uniform(size=(1, outputLayerNeurons))\n",
    "\n",
    "print(\"Initial hidden weights: \", end='')\n",
    "print(*hidden_weights)\n",
    "print(\"Initial hidden biases: \", end='')\n",
    "print(*hidden_bias)\n",
    "print(\"Initial output weights: \", end='')\n",
    "print(*output_weights)\n",
    "print(\"Initial output biases: \", end='')\n",
    "print(*output_bias)\n",
    "\n",
    "\n",
    "# Training algorithm\n",
    "for epoch in range(epochs):\n",
    "    # Forward Propagation\n",
    "    hidden_layer_activation = np.dot(inputs, hidden_weights) + hidden_bias\n",
    "    hidden_layer_output = sigmoid(hidden_layer_activation)\n",
    "\n",
    "    output_layer_activation = np.dot(hidden_layer_output, output_weights) + output_bias\n",
    "    predicted_output = sigmoid(output_layer_activation)\n",
    "\n",
    "    # Backpropagation\n",
    "    error = expected_output - predicted_output\n",
    "    d_predicted_output = error * sigmoid_derivative(predicted_output)\n",
    "    error_hidden_layer = d_predicted_output.dot(output_weights.T)\n",
    "    d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "    # Updating Weights and Biases\n",
    "    output_weights += hidden_layer_output.T.dot(d_predicted_output) * lr\n",
    "    output_bias += np.sum(d_predicted_output, axis=0, keepdims=True) * lr\n",
    "    hidden_weights += inputs.T.dot(d_hidden_layer) * lr\n",
    "    hidden_bias += np.sum(d_hidden_layer, axis=0, keepdims=True) * lr\n",
    "\n",
    "    # Calculate cost at each epoch\n",
    "    current_error = np.mean(np.square(expected_output - sigmoid(np.dot(sigmoid(np.dot(inputs, hidden_weights) + hidden_bias), output_weights) + output_bias)))\n",
    "\n",
    "    # Check for convergence\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}: Error = {current_error}\")\n",
    "        if np.abs(current_error) < 0.01:  # Check if error change is below threshold\n",
    "            print(f\"Converged at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "print(\"Final hidden weights: \", end='')\n",
    "print(*hidden_weights)\n",
    "print(\"Final hidden bias: \", end='')\n",
    "print(*hidden_bias)\n",
    "print(\"Final output weights: \", end='')\n",
    "print(*output_weights)\n",
    "print(\"Final output bias: \", end='')\n",
    "print(*output_bias)\n",
    "\n",
    "print(\"\\nOutput from neural network after 10,000 epochs: \", end='')\n",
    "print(*predicted_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78a80b5-6fef-4d9a-b045-d5e2e14672fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
